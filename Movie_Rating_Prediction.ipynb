{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Refernece\n",
        "\n",
        "1.   https://www.kaggle.com/code/bhsraman/predict-movie-ratings-via-machine-learning/notebook\n",
        "2.   https://www.kaggle.com/code/carolzhangdc/predict-imdb-score-with-data-mining-algorithms\n",
        "\n"
      ],
      "metadata": {
        "id": "ZTyW8f4t9ITJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9uCHPHJ8JKi"
      },
      "outputs": [],
      "source": [
        "#Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The OS module in Python provides functions for creating and removing a directory (folder),\n",
        "# fetching its contents, changing and identifying the current directory, etc. You first need to import\n",
        "# the os module to interact with the underlying operating system.\n",
        "import os\n",
        "os.chdir('/content/drive/Shareddrives/AML Final Project/data/')"
      ],
      "metadata": {
        "id": "lYlDIKCq8bCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Modules\n",
        "import io\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import json #converting JSON to lists for dataframe\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import base64\n",
        "import codecs\n",
        "from IPython.display import HTML\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "zMZl13S69hkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merging the two csv files\n",
        "movie1 = pd.read_csv(\"/content/drive/Shareddrives/AML Final Project/data/tmdb_5000_movies.csv\")\n",
        "movie2 = pd.read_csv(\"/content/drive/Shareddrives/AML Final Project/data/tmdb_5000_credits.csv\")\n",
        "\n",
        "movies = movie1.merge(movie2,left_on='id',right_on='movie_id',how='left')\n",
        "\n"
      ],
      "metadata": {
        "id": "ESYrw4Gq9htI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies.head()"
      ],
      "metadata": {
        "id": "yb47erH__OyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Proof that movies with 0.0 rating only have vote count of 0 or 1\n",
        "counts = movies[(movies['vote_average']==0)]['vote_count'] # get vote counts for all movies that have a rating of 0.0\n",
        "\n",
        "print(\"Unique vote counts for movies with 0.0 rating\")\n",
        "for u in set(counts):\n",
        "    print(u)"
      ],
      "metadata": {
        "id": "HAWbgKQ29hzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove 0.0 rated movies from dataframe\n",
        "movies = movies[(movies['vote_average']!=0)]"
      ],
      "metadata": {
        "id": "vtheCK599h2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies.sample(5)"
      ],
      "metadata": {
        "id": "c3FEWh2v9h5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies.describe(include = \"all\")"
      ],
      "metadata": {
        "id": "FIPr9edn9h7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies.info()"
      ],
      "metadata": {
        "id": "mPESqtdY9h-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({'Total missing values':movies.isna().sum(),\n",
        "              'Percentage':(movies.isna().sum()/len(movies))*100})"
      ],
      "metadata": {
        "id": "zR-TTbMh9iEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_list(df, feature_names_list): #df: dataframe, feature_names: list of all features to convert from JSON to list\n",
        "    for feature_name in feature_names_list:\n",
        "        print(\"Current:\", feature_name)\n",
        "        #STEP 1: convert JSON format to a list\n",
        "        df[feature_name]=df[feature_name].apply(json.loads)\n",
        "        #Two cases here: Feature is crew, or feature is not crew\n",
        "        if feature_name == 'crew': #if crew, due to large size, want to limit to most influential members: director, editor, cinematographer, screenplay, and composer\n",
        "            for index,i in zip(df.index,df[feature_name]):\n",
        "                feature_list_1=[]\n",
        "                limit = 10\n",
        "                if len(i) < 10:\n",
        "                    limit = len(i)\n",
        "                for j in range(limit): #top 10 crew members\n",
        "                    feature_list_1.append((i[j]['name'])) # the key 'name' contains the name of the a sub-feature (ex: sci-fi in genres)\n",
        "                df.loc[index,feature_name]= str(feature_list_1)\n",
        "\n",
        "        elif feature_name == 'cast': #Another special case. Only want top 5 cast members (most infulential)\n",
        "            for index,i in zip(df.index,df[feature_name]):\n",
        "                feature_list_1=[]\n",
        "                if len(i) > 5:\n",
        "                    limit = 5\n",
        "                else:\n",
        "                    limit = len(i)\n",
        "                for j in range(limit): #top 5 (JSON format already has this sorted)\n",
        "                    feature_list_1.append((i[j]['name']))\n",
        "                df.loc[index,feature_name]= str(feature_list_1)\n",
        "        else:\n",
        "            for index,i in zip(df.index,df[feature_name]):\n",
        "                feature_list_1=[]\n",
        "                for j in range(len(i)):\n",
        "                    feature_list_1.append((i[j]['name']))\n",
        "                df.loc[index,feature_name]= str(feature_list_1)\n",
        "\n",
        "        #STEP 2: clean up and transform into unsorted list\n",
        "        df[feature_name] = df[feature_name].str.strip('[]').str.replace(' ','').str.replace(\"'\",'')\n",
        "        df[feature_name] = df[feature_name].str.split(',')\n",
        "\n",
        "        #STEP 3: Sort list elements\n",
        "        for i,j in zip(df[feature_name],df.index):\n",
        "            features_list_2=i\n",
        "            features_list_2.sort()\n",
        "            df.loc[j,feature_name]=str(features_list_2)\n",
        "        df[feature_name]=df[feature_name].str.strip('[]').str.replace(' ','').str.replace(\"'\",'')\n",
        "        lst = df[feature_name].str.split(',')\n",
        "        if len(lst) == 0:\n",
        "            df[feature_name] = None\n",
        "        else:\n",
        "            df[feature_name]= df[feature_name].str.split(',')\n",
        "    return df"
      ],
      "metadata": {
        "id": "v3xRDjZt9iG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies = to_list(movies, ['genres', 'keywords', 'production_companies', 'cast', 'crew']) #function call"
      ],
      "metadata": {
        "id": "b7z0IhnvAEql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_drop = []\n",
        "for i in movies.index:\n",
        "    if (movies['production_companies'][i] == [''] and movies['cast'][i] == [''] and\n",
        "        movies['crew'][i] == ['']):\n",
        "        to_drop.append(i)\n",
        "print('Dropping', str(len(to_drop)), 'movies.')\n",
        "movies = movies.drop(to_drop, axis = 0)"
      ],
      "metadata": {
        "id": "kiCZmPoMAEv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies.shape[0]"
      ],
      "metadata": {
        "id": "UtH4AizDAE2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_shortened = movies[['id','original_title','genres','cast', 'crew', 'production_companies', 'keywords', 'vote_average']]"
      ],
      "metadata": {
        "id": "w4lSf0LpAE5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_shortened.sample(10)"
      ],
      "metadata": {
        "id": "7GiNlmDbAE8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplots(figsize=(12,10))\n",
        "n, bins, patches = plt.hist(movies_shortened['vote_average'], 30, density=1, facecolor='g', alpha=0.75)\n",
        "\n",
        "plt.xlabel('Vote_average')\n",
        "plt.ylabel('Occurence')\n",
        "plt.title('Distribution of voter average')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "print(\"Minimum of Ratings:\", round(min(movies_shortened['vote_average']),2))\n",
        "print(\"Maximum of Ratings:\", round(max(movies_shortened['vote_average']),2))\n",
        "print(\"Average of Ratings:\", round(np.mean(movies_shortened['vote_average']),2))\n",
        "print(\"Variance of Ratings:\",round(np.var(movies_shortened['vote_average']),2))"
      ],
      "metadata": {
        "id": "wPTqBSohAE-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_list(df, feature_name): #create a list of all unique feature values\n",
        "    #Step 1: track all ratings associated with each feature in a dictionary\n",
        "    feature_dict = {}\n",
        "    for index, row in df.iterrows():\n",
        "        feat = row[feature_name]\n",
        "        for sub_feat in feat:\n",
        "            if sub_feat not in feature_dict:\n",
        "                feature_dict[sub_feat] = (df['vote_average'][index], 1) #\n",
        "            else:\n",
        "                feature_dict[sub_feat] = (feature_dict[sub_feat][0] + (df['vote_average'][index]), feature_dict[sub_feat][1] + 1)\n",
        "    #Step 2: calculate average ratings for each feature\n",
        "    for key in feature_dict:\n",
        "        feature_dict[key] = feature_dict[key][0]/feature_dict[key][1] #average of all vote_averages\n",
        "\n",
        "    #Step 3: create and sort a list of tuples (dictionary value, key)\n",
        "    lst = list()\n",
        "    for name in feature_dict:\n",
        "        lst.append((feature_dict[name],name))\n",
        "    lst = sorted(lst)\n",
        "    #step 4: create a list of only the feature names, from lowest rating to highest rating\n",
        "    feature_list = list()\n",
        "    ratings_list = list()\n",
        "    for element in lst:\n",
        "        feature_list.append(element[1])\n",
        "        ratings_list.append(element[0])\n",
        "\n",
        "    #get the variance of the ratings. This is helpful for determining the usefulness of the information (to be displayed in below plot)\n",
        "    var = round(np.var(ratings_list),3)\n",
        "\n",
        "    #before returning the list, do a quick visualization to show that generate_list works\n",
        "    fig, ax = plt.subplots(figsize=(6,5))\n",
        "    if feature_name != 'genres':\n",
        "        n = 50 # sample at intervals of n\n",
        "    else:\n",
        "        n = 1\n",
        "    X = [] #sample for associated movie(s) rating average\n",
        "    Y = [] #sample for feature names\n",
        "    for i in range(0, len(feature_list) - 1, n):\n",
        "        X.append(ratings_list[i])\n",
        "        Y.append(feature_list[i])\n",
        "\n",
        "    y_pos = np.arange(len(Y))\n",
        "    ax.barh(y_pos, X, align='center')\n",
        "    #ax.set_yticklabels(Y)\n",
        "    ax.invert_yaxis()  # labels read top-to-bottom\n",
        "\n",
        "    ax.set_xlabel('Overall average movie ratings')\n",
        "    ax.set_ylabel(feature_name + ' sample list index')\n",
        "    ax.set_title(feature_name + ' to associated movie(s) performance (' + str(int(len(feature_list)/n)) + ' samples), variance: ' + str(var))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return feature_list\n"
      ],
      "metadata": {
        "id": "kIPmjP4RAFBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genres_list = generate_list(movies_shortened, 'genres')"
      ],
      "metadata": {
        "id": "HrzjGULoDtB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(movies_shortened)"
      ],
      "metadata": {
        "id": "8YC7QFpiDtKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cast_list = generate_list(movies_shortened, 'cast')"
      ],
      "metadata": {
        "id": "SCnSAUXwDtNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crew_list = generate_list(movies_shortened, 'crew')"
      ],
      "metadata": {
        "id": "eJFI7DSKDtQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prod_companies_list = generate_list(movies_shortened, 'production_companies')"
      ],
      "metadata": {
        "id": "M_FszIdiDtS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keywords_list = generate_list(movies_shortened, 'keywords')"
      ],
      "metadata": {
        "id": "oydyAp2BEXul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_shortened = movies_shortened[['id', 'original_title', 'cast', 'crew', 'production_companies', 'keywords','vote_average']]"
      ],
      "metadata": {
        "id": "ajldcqCqEXx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_bin_array(this_list, all_features):\n",
        "    bin_list = []\n",
        "    for element in all_features:\n",
        "        if element in this_list:\n",
        "            bin_list.append(1)\n",
        "        else:\n",
        "            bin_list.append(0)\n",
        "    return bin_list"
      ],
      "metadata": {
        "id": "i416DkDsEX1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_shortened['cast'] = movies_shortened['cast'].apply(lambda x: calculate_bin_array(x, cast_list))"
      ],
      "metadata": {
        "id": "2YO6A4pNEX4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_shortened['crew'] = movies_shortened['crew'].apply(lambda x: calculate_bin_array(x, crew_list))"
      ],
      "metadata": {
        "id": "OIDbyhRlEX7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_shortened['production_companies'] = movies_shortened['production_companies'].apply(lambda x: calculate_bin_array(x, prod_companies_list))"
      ],
      "metadata": {
        "id": "TLCdSClZEX-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_shortened['keywords'] = movies_shortened['keywords'].apply(lambda x: calculate_bin_array(x, keywords_list))"
      ],
      "metadata": {
        "id": "mCzskpRiEYBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_shortened.sample(10)"
      ],
      "metadata": {
        "id": "4wzLtimrEYD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_bin(mov):\n",
        "    cast_bin = mov[2]\n",
        "    cast_index = []\n",
        "    # create arrays of indeces where bin number is one\n",
        "    for i in range(len(cast_bin)):\n",
        "        if cast_bin[i] == 1:\n",
        "            cast_index.append(i)\n",
        "\n",
        "    crew_bin = mov[3]\n",
        "    crew_index = []\n",
        "    for i in range(len(crew_bin)):\n",
        "        if crew_bin[i] == 1:\n",
        "            crew_index.append(i)\n",
        "\n",
        "    prod_bin = mov[4]\n",
        "    prod_index = []\n",
        "    for i in range(len(prod_bin)):\n",
        "        if prod_bin[i] == 1:\n",
        "            prod_index.append(i)\n",
        "\n",
        "    keywords_bin = mov[5]\n",
        "    keywords_index = []\n",
        "    for i in range(len(keywords_bin)):\n",
        "        if keywords_bin[i] == 1:\n",
        "            keywords_index.append(i)\n",
        "\n",
        "    font = {'family': 'serif',\n",
        "        'color':  'red',\n",
        "        'weight': 'normal',\n",
        "        'size': 10,\n",
        "        }\n",
        "\n",
        "    fig, ax = plt.subplots(4,1,figsize=(5,1))\n",
        "    plt.subplots_adjust(hspace = 5)\n",
        "    ax[0].scatter(cast_index, np.zeros_like(cast_index), vmin=-2)\n",
        "    ax[0].set_title('Cast', loc = 'left', fontdict=font)\n",
        "    ax[0].set_xlim(0,len(cast_bin))\n",
        "    ax[0].set_yticks([])\n",
        "    ax[0].set_xticks([])\n",
        "\n",
        "    ax[1].scatter(crew_index, np.zeros_like(crew_index), vmin=-2)\n",
        "    ax[1].set_title('Crew', loc = 'left', fontdict=font)\n",
        "    ax[1].set_xlim(0,len(crew_bin))\n",
        "    ax[1].set_yticks([])\n",
        "    ax[1].set_xticks([])\n",
        "\n",
        "    ax[2].scatter(prod_index, np.zeros_like(prod_index), vmin=-2)\n",
        "    ax[2].set_title('Production companies', loc = 'left', fontdict=font)\n",
        "    ax[2].set_xlim(0,len(prod_bin))\n",
        "    ax[2].set_yticks([])\n",
        "    ax[2].set_xticks([])\n",
        "\n",
        "    ax[3].scatter(keywords_index, np.zeros_like(keywords_index), vmin=-2)\n",
        "    ax[3].set_title('Keywords', loc = 'left', fontdict=font)\n",
        "    ax[3].set_xlim(0,len(keywords_bin))\n",
        "    ax[3].set_yticks([])\n",
        "    ax[3].set_xticks([])\n"
      ],
      "metadata": {
        "id": "MXZah4VMw1Ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_sample = movies_shortened.sample(5)"
      ],
      "metadata": {
        "id": "o8pXtILHw1T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Movie: ' + movies_sample.iloc[0][1] + '\\nRating: ' + str(movies_sample.iloc[0][-1]) + '\\n')\n",
        "plot_bin(movies_sample.iloc[0])"
      ],
      "metadata": {
        "id": "hdqRehRYw1W0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Movie:' + movies_sample.iloc[1][1] + '\\nRating: ' + str(movies_sample.iloc[1][-1]) + '\\n')\n",
        "plot_bin(movies_sample.iloc[1])"
      ],
      "metadata": {
        "id": "GiuVhZs9w1g_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Movie:' + movies_sample.iloc[2][1] + '\\nRating: ' + str(movies_sample.iloc[2][-1]) + '\\n')\n",
        "plot_bin(movies_sample.iloc[2])"
      ],
      "metadata": {
        "id": "plGleTUhw1lV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Movie:' + movies_sample.iloc[3][1] + '\\nRating: ' + str(movies_sample.iloc[3][-1]) + '\\n')\n",
        "plot_bin(movies_sample.iloc[3])"
      ],
      "metadata": {
        "id": "AjW4sr3X0uQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Movie:' + movies_sample.iloc[4][1] + '\\nRating: ' + str(movies_sample.iloc[4][-1]) + '\\n')\n",
        "plot_bin(movies_sample.iloc[4])"
      ],
      "metadata": {
        "id": "x7Rd4eC60uTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_arr(arr, n_splits):\n",
        "\n",
        "    # looping till length l\n",
        "    for i in range(0, len(arr), n_splits):\n",
        "        yield arr[i:i + n_splits]\n",
        "\n",
        "def find_concentration(arr, n = 100): # n is the number of concentration points to find\n",
        "    #seperate array into batches\n",
        "    batches = list(split_arr(arr,int(len(arr)/n)))\n",
        "    concentrations = []\n",
        "    for i in range(len(batches)):\n",
        "        point = 0\n",
        "        num_ones = 0\n",
        "        for j in range(len(batches[i])):\n",
        "            if batches[i][j] == 1:\n",
        "                point += j + (i * int(len(arr)/n)) # adding correction for batches\n",
        "                num_ones += 1\n",
        "        if num_ones > 0:\n",
        "            point = point/num_ones\n",
        "            concentrations.append((point,num_ones))\n",
        "    return concentrations"
      ],
      "metadata": {
        "id": "SM8PWAOk0uVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_concentrations(df, feature_names):\n",
        "    for feature_name in feature_names:\n",
        "        print('feature: ', feature_name)\n",
        "        df[feature_name] = df[feature_name].apply(lambda x: find_concentration(x))\n",
        "    return df"
      ],
      "metadata": {
        "id": "RsUxFXh20uYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_shortened = to_concentrations(movies_shortened, ['cast', 'crew', 'production_companies', 'keywords'])"
      ],
      "metadata": {
        "id": "1b2sxk0r0ubg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_shortened.sample(10)"
      ],
      "metadata": {
        "id": "rgfsugP10ueA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def w_avg(arr):\n",
        "    weight = 0 #weight\n",
        "    s = 0 # position*weight\n",
        "    for element in arr:\n",
        "        s += (element[0] * element[1])\n",
        "        weight += element[1]\n",
        "    return s/weight #weighted average"
      ],
      "metadata": {
        "id": "ei2Ocnqt0ug6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_weighted_avg(df, feature_names):\n",
        "    for feature_name in feature_names:\n",
        "        print('Current: ', feature_name)\n",
        "        df[feature_name] = df[feature_name].apply(lambda x: w_avg(x))\n",
        "    return df"
      ],
      "metadata": {
        "id": "q3J-Ratw0ujg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_shortened = to_weighted_avg(movies_shortened, ['cast', 'crew', 'production_companies', 'keywords'])"
      ],
      "metadata": {
        "id": "S0i7tmrj0umX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_shortened['vote_average'] = movies['vote_average']"
      ],
      "metadata": {
        "id": "vMEB7ep60upJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_shortened.sample(10)"
      ],
      "metadata": {
        "id": "r_sbULka1GP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat_df = movies_shortened[['cast', 'crew', 'production_companies', 'keywords']] #extract only features from df, and scale"
      ],
      "metadata": {
        "id": "lN4EoKcY1GTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "feat_scaled = pd.DataFrame(scaler.fit_transform(feat_df.astype(float)))\n",
        "feat_scaled.index = feat_df.index\n",
        "feat_scaled.columns = feat_df.columns\n",
        "\n",
        "#Seperate dataframe for target\n",
        "target_df = pd.DataFrame()\n",
        "target_df['ratings'] =  movies_shortened['vote_average']"
      ],
      "metadata": {
        "id": "29TtL96O1GWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat_scaled.sample(10)"
      ],
      "metadata": {
        "id": "TRKARzu31Gc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(2,2, figsize=(24,20))\n",
        "\n",
        "ax[0,0].scatter(target_df['ratings'], feat_scaled['cast'], facecolor='blue')\n",
        "ax[0,0].set_xlabel('rating')\n",
        "ax[0,0].set_ylabel('cast normalized')\n",
        "ax[0,0].set_title('cast')\n",
        "\n",
        "ax[1,0].scatter(target_df['ratings'], feat_scaled['crew'], facecolor='green')\n",
        "ax[1,0].set_xlabel('rating')\n",
        "ax[1,0].set_ylabel('crew normalized')\n",
        "ax[1,0].set_title('crew')\n",
        "\n",
        "ax[0,1].scatter(target_df['ratings'], feat_scaled['production_companies'], facecolor='red')\n",
        "ax[0,1].set_xlabel('rating')\n",
        "ax[0,1].set_ylabel('production companies normalized')\n",
        "ax[0,1].set_title('Production Companies')\n",
        "\n",
        "ax[1,1].scatter(target_df['ratings'], feat_scaled['keywords'], facecolor='orange')\n",
        "ax[1,1].set_xlabel('rating')\n",
        "ax[1,1].set_ylabel('keywords normalized')\n",
        "ax[1,1].set_title('keywords')\n",
        "\n",
        "fig.suptitle(\"Corrlation between a movie's features and its rating\")"
      ],
      "metadata": {
        "id": "LjfMgM_61GeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "def train_test_val_split(df_feat, df_target, train_frac):\n",
        "    train_features, test_features, train_target, test_target = train_test_split(df_feat, df_target, test_size = train_frac) #splitting training from rest of the dataset\n",
        "    return (train_features, train_target), (test_features, test_target)"
      ],
      "metadata": {
        "id": "cpFLi2Yi1GfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(features_train, target_train), (features_test, target_test) = train_test_val_split(feat_scaled, target_df,0.7)"
      ],
      "metadata": {
        "id": "vxS3s6ir1Q6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_train.head()"
      ],
      "metadata": {
        "id": "BwlKW4wC1Q9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import BayesianRidge"
      ],
      "metadata": {
        "id": "U6PHZjQb1Q_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg = BayesianRidge()\n",
        "reg.fit(features_train.values, target_train)"
      ],
      "metadata": {
        "id": "zgG1tnLo1RCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_pred = reg.predict(features_test.values)"
      ],
      "metadata": {
        "id": "6e1CZ65O1RFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.axis([0,10,0,10])\n",
        "plt.scatter(target_test, target_pred)\n",
        "\n",
        "index_arr = [n for n in range(11)]\n",
        "plt.plot(index_arr,'r--')\n",
        "plt.xlabel(\"Movie Ratings\")\n",
        "plt.ylabel(\"Predicted Ratings\")\n",
        "plt.title(\"Movie ratings vs Predicted ratings\")"
      ],
      "metadata": {
        "id": "tIiExbL51RIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "score = r2_score(target_test, target_pred)\n",
        "\n",
        "print(\"R^2 Score for predictions:\", score)"
      ],
      "metadata": {
        "id": "YJjYIuki1RLR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}